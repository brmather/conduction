<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>conduction.inversion.nd_inverse_conduction API documentation</title>
<meta name="description" content="Copyright 2017 Ben Mather â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>conduction.inversion.nd_inverse_conduction</code></h1>
</header>
<section id="section-intro">
<p>Copyright 2017 Ben Mather</p>
<p>This file is part of Conduction <a href="https://git.dias.ie/itherc/conduction/">https://git.dias.ie/itherc/conduction/</a></p>
<p>Conduction is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or any later version.</p>
<p>Conduction is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with Conduction.
If not, see <a href="http://www.gnu.org/licenses/">http://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Copyright 2017 Ben Mather

This file is part of Conduction &lt;https://git.dias.ie/itherc/conduction/&gt;

Conduction is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or any later version.

Conduction is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with Conduction.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
&#34;&#34;&#34;

try: range = xrange
except: pass

import numpy as np
from ..interpolation import RegularGridInterpolator, KDTreeInterpolator
from ..mesh import MeshVariable
from ..tools import sum_duplicates
from .objective_variables import InvPrior, InvObservation
from .grad_ad import gradient_ad as ad_grad

from mpi4py import MPI
from petsc4py import PETSc
comm = MPI.COMM_WORLD


class InversionND(object):

    def __init__(self, lithology, mesh, lithology_index=None, **kwargs):
        self.mesh = mesh

        # update internal mask structures
        self.update_lithology(lithology, lithology_index)


        # Custom linear / nearest-neighbour interpolator
        self.interp = RegularGridInterpolator(mesh.grid_coords[::-1],\
                                              np.zeros(mesh.n),\
                                              bounds_error=False, fill_value=np.nan)

        self.ndinterp = KDTreeInterpolator(mesh.coords, np.zeros(mesh.nn),\
                                           bounds_error=False, fill_value=0.0)

        # Get weights for ghost points
        mesh.lvec.set(1.0)
        mesh.gvec.set(0.0)
        mesh.dm.localToGlobal(mesh.lvec, mesh.gvec, addv=True)
        mesh.dm.globalToLocal(mesh.gvec, mesh.lvec)
        self.ghost_weights = np.rint(mesh.lvec.array)


        # We assume uniform grid spacing for now
        delta = []
        for i in range(0, mesh.dim):
            dx = np.diff(mesh.grid_coords[i])
            delta.append(dx.mean())
        self.grid_delta = delta


        # objective function dictionaries
        self.observation = {}
        self.prior = {}


        # Initialise linear solver
        self.ksp = self._initialise_ksp(**kwargs)

        # these should be depreciated soon
        self.temperature = self.mesh.gvec.duplicate()
        self._temperature = self.mesh.gvec.duplicate()
        self.iii = 0


    def update_lithology(self, new_lithology, lithology_index=None):
        &#34;&#34;&#34;
        Update the configuration of lithologies.

        Internal mask structures are updated to reflect the change in
        lithology configuration.

        Arguments
        ---------
         new_lithology   : field on the mesh with integers indicating
            : the position of particular lithologies
         lithology_index : array corresponding to the total number of
            : integers in new_lithology
        
        Notes
        -----
         lithology_index is determined from the min/max of elements
         in new_lithology if lithology_index=None
        &#34;&#34;&#34;

        new_lithology = np.array(new_lithology).ravel()

        # sync across processors
        new_lithology = self.mesh.sync(new_lithology)
        new_lithology = new_lithology.astype(np.int)

        if type(lithology_index) == type(None):
            # query global vector for minx/max
            iloc, lith_min = self.mesh.gvec.min()
            iloc, lith_max = self.mesh.gvec.max()

            # create lithology index
            lithology_index = np.arange(int(lith_min), int(lith_max)+1)


        nl = len(lithology_index)
        lithology_mask = [i for i in range(nl)]

        # create lithology mask
        for i, index in enumerate(lithology_index):
            lithology_mask[i] = np.nonzero(new_lithology == index)[0]

        self.lithology_mask = lithology_mask
        self.lithology_index = lithology_index
        self._lithology = new_lithology

        return

    @property
    def lithology(self):
        return self._lithology
    @lithology.setter
    def lithology(self, new_lithology):
        self.update_lithology(new_lithology)


    def _initialise_ksp(self, matrix=None, atol=1e-10, rtol=1e-50, **kwargs):
        &#34;&#34;&#34;
        Initialise linear solver object
        &#34;&#34;&#34;
        if matrix is None:
            matrix = self.mesh.mat

        solver = kwargs.pop(&#39;solver&#39;, &#39;gmres&#39;)
        precon = kwargs.pop(&#39;pc&#39;, None)

        ksp = PETSc.KSP().create(comm)
        ksp.setType(solver)
        ksp.setOperators(matrix)
        ksp.setTolerances(atol, rtol)
        if precon is not None:
            pc = ksp.getPC()
            pc.setType(precon)
        ksp.setFromOptions()
        return ksp

    def get_boundary_conditions(self):
        &#34;&#34;&#34;
        Retrieve the boundary conditions so they can be restored.
        This is only useful in the adjoint linear solve where we must assert
        Dirichlet BCs (I think)

        order is [minX, maxX, minY, maxY, minZ, maxZ]

        Returns
        -------
         bc_vals : values at the boundary conditions
         bc_flux : whether it is a Neumann boundary condition

        &#34;&#34;&#34;
        dim = self.mesh.dim
        bc_vals = np.empty(dim*2)
        bc_flux = np.empty(dim*2, dtype=bool)

        wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

        for i in range(0, dim):
            w0, w1 = wall[i]
            i0, i1 = i*2, i*2+1

            bc_vals[i0] = self.mesh.bc[w0][&#34;val&#34;]
            bc_flux[i0] = self.mesh.bc[w0][&#34;flux&#34;]

            bc_vals[i1] = self.mesh.bc[w1][&#34;val&#34;]
            bc_flux[i1] = self.mesh.bc[w1][&#34;flux&#34;]

        return bc_vals, bc_flux


    def set_boundary_conditions(self, bc_vals, bc_flux):
        &#34;&#34;&#34;
        Set the boundary conditions easily using two vectors
        order is [minX, maxX, minY, maxY, minZ, maxZ]

        Parameters
        -------
         bc_vals : values at the boundary conditions
         bc_flux : whether it is a Neumann boundary condition

        &#34;&#34;&#34;
        dim = self.mesh.dim
        if len(bc_vals) != len(bc_flux) or len(bc_vals) != dim*2:
            raise ValueError(&#34;Input vectors should be of size {}&#34;.format(dim*2))

        wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

        for i in range(0, dim):
            w0, w1 = wall[i]
            i0, i1 = i*2, i*2+1

            self.mesh.bc[w0][&#34;val&#34;]  = bc_vals[i0]
            self.mesh.bc[w0][&#34;flux&#34;] = bc_flux[i0]

            self.mesh.bc[w1][&#34;val&#34;]  = bc_vals[i1]
            self.mesh.bc[w1][&#34;flux&#34;] = bc_flux[i1]


    def add_observation(self, **kwargs):
        &#34;&#34;&#34;
        Add an observation to the Inversion routine.
        These will automatically be called when the objective function is called
        and will handle interpolation.

        &#34;&#34;&#34;
        interp = self.interp
        interp.values = self.ghost_weights.reshape(self.mesh.n)

        for arg in kwargs:
            obs = kwargs[arg]
            if type(obs) is not InvObservation:
                raise TypeError(&#34;Need to pass {} instead of {}&#34;.format(InvObservation,type(obs)))

            # add interpolation information to obs
            w = interp(obs.coords[:,::-1])
            w = 1.0/np.floor(w + 1e-12)
            offproc = np.isnan(w)
            w[offproc] = 0.0 # these are weighted with zeros
            obs.w = w # careful with 2x ghost nodes+

            # store in dictionary
            self.observation[arg] = obs


    def add_prior(self, **kwargs):
        &#34;&#34;&#34;
        Add a prior to the Inversion routine
        &#34;&#34;&#34;

        for arg in kwargs:
            prior = kwargs[arg]
            if type(prior) is not InvPrior:
                raise TypeError(&#34;Need to pass {} instead of {}&#34;.format(InvPrior, type(prior)))

            prior.w = 1.0

            # store in dictionary
            self.prior[arg] = prior


    def objective_routine(self, **kwargs):
        &#34;&#34;&#34;
        This always comes at the end of the forward model (beginning of the adjoint)
        so we can safely roll interpolation, cost into one method.

        Argument is a field if it is an observation - so that we can interpolate it.
        &#34;&#34;&#34;

        # ensure an objective function is provided
        # if self.objective_function is None:
            # raise ValueError(&#34;Pass an objective function&#34;)

        c = np.array(0.0) # local prior values same as global
        c_obs = np.array(0.0) # obs have to be summed over all procs
        c_all = np.array(0.0) # sum of all obs

        for arg in kwargs:
            val = kwargs[arg]
            if arg in self.prior:
                prior = self.prior[arg]

                if prior.cov is None:
                    c += self.objective_function(val, prior.v, prior.dv)
                else:
                    c += self.objective_function_lstsq(val, prior.v, prior.cov)
            elif arg in self.observation:
                obs = self.observation[arg]

                # interpolation
                ival = self.interpolate(val, obs.coords)

                # weighting for ghost nodes
                if obs.cov is None:
                    c_obs += self.objective_function(ival*obs.w, obs.v*obs.w, obs.dv)
                else:
                    c_obs += self.objective_function_lstsq(ival*obs.w, obs.v*obs.w, obs.cov)



        comm.Allreduce([c_obs, MPI.DOUBLE], [c_all, MPI.DOUBLE], op=MPI.SUM)
        c += c_all
        return c

    def objective_routine_ad(self, **kwargs):

        dcdv = 0.0

        for arg in kwargs:
            val = kwargs[arg]
            if arg in self.prior:
                prior = self.prior[arg]
                if prior.cov is None:
                    dcdv = self.objective_function_ad(val, prior.v, prior.dv)
                else:
                    dcdv = self.objective_function_lstsq_ad(val, prior.v, prior.cov)

            elif arg in self.observation:
                obs = self.observation[arg]

                ival = self.interpolate(val, obs.coords)


                if obs.cov is None:
                    dcdinterp = self.objective_function_ad(ival, obs.v, obs.dv)
                else:
                    dcdinterp = self.objective_function_lstsq_ad(ival*obs.w, obs.v*obs.w, obs.cov)

                # interpolation
                dcdv = self.interpolate_ad(dcdinterp, val, obs.coords)
                # print arg, np.shape(val), np.shape(ival), np.shape(dcdv)

                # sync
                dcdv = self.mesh.sync(dcdv)
            else:
                dcdv = np.zeros_like(val)

        return dcdv


    def create_covariance_matrix(self, sigma_x0, width=1, indexing=&#39;xy&#39;, fn=None, *args):
        &#34;&#34;&#34;
        Create a covariance matrix assuming some function for variables on the mesh
        By default this is Gaussian.

        Arguments
        ---------
         sigma_x0 : uncertainty values to insert into matrix
         width    : width of stencil for matrix (int)
            i.e. extended number of neighbours for each node
         indexing : use the xy coordinates of the mesh nodes or indices
            set to &#39;xy&#39; or &#39;ij&#39;
         fn       : function to apply (default is Gaussian)
         *args    : input arguments to pass to fn

        Returns
        -------
            mat : covariance matrix
        &#34;&#34;&#34;

        def gaussian_fn(sigma_x0, dist, length_scale):
            return sigma_x0**2 * np.exp(-dist**2/(2*length_scale**2))

        if type(fn) == type(None):
            fn = gaussian_fn

        nodes = self.mesh.nodes
        nn = self.mesh.nn
        n = self.mesh.n
        dim = self.mesh.dim

        if indexing == &#34;xy&#34;:
            coords = self.mesh.coords
        elif indexing == &#34;ij&#34;:
            ic = []
            for i in range(dim):
                ic.append( np.arange(n[i]) )
            cij = np.meshgrid(*ic, indexing=&#34;ij&#34;)

            for i in range(dim):
                cij[i] = cij[i].ravel()
            coords = np.column_stack(cij)

        # setup new stencil
        stencil_width = 2*self.mesh.dim*width + 1
        rows = np.empty((stencil_width, self.mesh.nn), dtype=PETSc.IntType)
        cols = np.empty((stencil_width, self.mesh.nn), dtype=PETSc.IntType)
        vals = np.empty((stencil_width, self.mesh.nn))
        index = np.pad(nodes.reshape(n), width, &#39;constant&#39;, constant_values=-1)
        sigma = np.pad(sigma_x0.reshape(n), width, &#39;constant&#39;, constant_values=0)

        closure = []
        for w in range(width, 0, -1):
            closure_array = self.mesh._get_closure_array(dim, w, width)
            closure.extend(closure_array[:-1])
        closure.append(closure_array[-1]) # centre node at last

        # create closure object
        closure = self.mesh._create_closure_object(closure, width)


        for i in range(0, stencil_width):
            obj = closure[i]

            rows[i] = nodes
            cols[i] = index[obj].ravel()

            distance = np.linalg.norm(coords[cols[i]] - coords, axis=1)
            vals[i] = fn(sigma[obj].ravel(), distance, *args)

        vals[cols &lt; 0] = 0.0
        vals[-1] = 0.0

        row = rows.ravel()
        col = cols.ravel()
        val = vals.ravel()

        # mask off-grid entries and sum duplicates
        mask = col &gt;= 0
        row, col, val = sum_duplicates(row[mask], col[mask], val[mask])

        nnz = np.bincount(row)
        indptr = np.insert(np.cumsum(nnz),0,0)

        nnz = (stencil_width, dim*2)
        mat = self.mesh._initialise_matrix(nnz=nnz)
        mat.assemblyBegin()
        mat.setValuesLocalCSR(indptr.astype(PETSc.IntType), col, val)
        mat.assemblyEnd()

        # set diagonal vector
        lvec = self.mesh.lvec
        gvec = self.mesh.gvec
        lvec.setArray(sigma_x0**2)
        self.mesh.dm.localToGlobal(lvec, gvec)
        mat.setDiagonal(gvec)
        return mat


    def create_covariance_matrix_kdtree(self, sigma_x0, width=1, indexing=&#39;xy&#39;, fn=None, *args):
        &#34;&#34;&#34;
        Create a covariance matrix assuming some function for variables on the mesh.
        By default this is Gaussian.

        This uses a KDTree to determine distance between nodes, rather than the
        matrix stencil indexing used by create_covariance_matrix
        

        Arguments
        ---------
         sigma_x0 : uncertainty values to insert into matrix
         width    : width of stencil for matrix (int)
            i.e. extended number of neighbours for each node
         indexing : use the xy coordinates of the mesh nodes or indices
            set to &#39;xy&#39; or &#39;ij&#39;
         fn       : function to apply (default is Gaussian)
         *args    : input arguments to pass to fn

        Returns
        -------
            mat : covariance matrix
        &#34;&#34;&#34;

        def gaussian_fn(sigma_x0, dist, length_scale):
            return sigma_x0**2 * np.exp(-dist**2/(2*length_scale**2))

        if type(fn) == type(None):
            fn = gaussian_fn

        nodes = self.mesh.nodes
        nn = self.mesh.nn
        n = self.mesh.n
        dim = self.mesh.dim

        if indexing == &#34;xy&#34;:
            coords = self.mesh.coords
            tree = self.ndinterp.tree
        elif indexing == &#34;ij&#34;:
            from scipy.spatial import cKDTree

            ic = []
            for i in range(dim):
                ic.append( np.arange(n[i]) )
            cij = np.meshgrid(*ic, indexing=&#34;ij&#34;)

            for i in range(dim):
                cij[i] = cij[i].ravel()
            coords = np.column_stack(cij)
            tree = cKDTree(coords)


        # find distance between coords and centroid
        dist = np.linalg.norm(coords - coords.mean(axis=0), axis=1)
        nnz = int(1.5*(dist &lt;= max_dist).sum())

        mat = self.mesh._initialise_matrix(nnz=(nnz,1))
        mat.assemblyBegin()

        for i in range(0, nn):
            idx = tree.query_ball_point(coords[i], max_dist)
            dist = np.linalg.norm(coords[i] - coords[idx], axis=1)
            
            row = i
            col = idx
            val = fn(sigma[idx], dist, *args, **kwargs)
            
            mat.setValues(row, col, val)

        mat.assemblyEnd()
        return mat


    def interpolate(self, field, xi, method=&#34;nearest&#34;):
        self.ndinterp.values = field #.reshape(self.mesh.n)
        return self.ndinterp(xi, method=method)

    def interpolate_ad(self, dxi, field, xi, method=&#34;nearest&#34;):
        self.ndinterp.values = field #.reshape(self.mesh.n)
        return self.ndinterp.adjoint(xi, dxi, method=method) #.ravel()

    def in_bounds(self, xi):
        &#34;&#34;&#34;
        Find if coordinates are inside the local processor bounds
        &#34;&#34;&#34;
        idx, d, bounds = self.ndinterp._find_indices(xi)
        return bounds


    def objective_function(self, x, x0, sigma_x0):
        return np.sum(0.5*(x - x0)**2/sigma_x0**2)

    def objective_function_ad(self, x, x0, sigma_x0):
        return 0.5*(2.0*x - 2.0*x0)/sigma_x0**2


    def objective_function_lstsq(self, x, x0, cov):
        &#34;&#34;&#34;
        Nonlinear least squares objective function
        &#34;&#34;&#34;
        ksp = self._initialise_ksp(cov, pc=&#39;lu&#39;)
        misfit = np.array(x - x0)
        lhs, rhs = cov.createVecs()
        rhs.set(0.0)
        lindices = np.arange(0, misfit.size, dtype=PETSc.IntType)
        rhs.setValues(lindices, misfit, PETSc.InsertMode.ADD_VALUES)
        rhs.assemble()
        ksp.solve(rhs, lhs)
        sol = rhs*lhs
        sol.scale(0.5)

        ksp.destroy()
        lhs.destroy()
        rhs.destroy()

        return sol.sum()/comm.size

    def objective_function_lstsq_ad(self, x, x0, cov):
        &#34;&#34;&#34;
        Adjoint of the nonlinear least squares objective function
        &#34;&#34;&#34;
        ksp = self._initialise_ksp(cov, pc=&#39;lu&#39;)

        misfit = np.array(x - x0)
        lhs, rhs = cov.createVecs()
        rhs.set(0.0)
        lindices = np.arange(0, misfit.size, dtype=PETSc.IntType)
        rhs.setValues(lindices, misfit, PETSc.InsertMode.ADD_VALUES)
        rhs.assemble()
        ksp.solve(rhs, lhs)

        toall, allvec = PETSc.Scatter.toAll(lhs)
        toall.scatter(lhs, allvec, PETSc.InsertMode.INSERT)

        ksp.destroy()
        lhs.destroy()
        return allvec.array


    def map(self, *args):
        &#34;&#34;&#34;
        Requires a tuple of vectors corresponding to an inversion variable
        these are mapped to the mesh.

        tuple(vec1, vec2, vecN) --&gt; tuple(field1, field2, fieldN)
        &#34;&#34;&#34;

        nf = len(args)
        nl = len(self.lithology_index)

        # preallocate local memory
        mesh_variables = np.zeros((nf, self.mesh.nn))

        # unpack vector to field
        for i in range(0, nl):
            idx = self.lithology_mask[i]
            for f in range(nf):
                mesh_variables[f,idx] = args[f][i]

        # sync fields across processors
        for f in range(nf):
            mesh_variables[f] = self.mesh.sync(mesh_variables[f])

        return list(mesh_variables)

    def map_ad(self, *args):
        &#34;&#34;&#34;
        Map mesh variables back to the list
        &#34;&#34;&#34;
        
        nf = len(args)
        nl = len(self.lithology_index)

        # sync fields across processors
        mesh_variables = np.zeros((nf, self.mesh.nn))
        for f in range(nf):
            mesh_variables[f] = self.mesh.sync(args[f])

        lith_variables = np.zeros((nf, self.lithology_index.size))
        all_lith_variables = np.zeros_like(lith_variables)

        for i in range(0, nl):
            idx = self.lithology_mask[i]
            for f in range(nf):
                lith_variables[f,i] += (mesh_variables[f]/self.ghost_weights)[idx].sum()

        comm.Allreduce([lith_variables, MPI.DOUBLE], [all_lith_variables, MPI.DOUBLE], op=MPI.SUM)

        return list(all_lith_variables)


    def create_wall_map(self, wall, *args):
        coords = self.mesh.coords
        dim = self.mesh.dim

        bbox = self.mesh.dm.getBoundingBox()
        sizes = self.mesh.dm.getSizes()

        # Setup boundary dictionary
        bc = dict()

        wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

        for i in range(0, dim):
            w0, w1 = wall[i]
            c0, c1 = bbox[i]
            m0, m1 = coords[:,i] == c0, coords[:,i] == c1

        
        self.boundary_index = boundary_index


    def map_wall(self, wall, *args):
        &#34;&#34;&#34;
        Map lists of arguments to a boundary wall


        &#34;&#34;&#34;

        if wall not in self.mesh.bc:
            raise ValueError(&#34;wall must be one of {}&#34;.format(self.mesh.bc.keys()))
        if len(args) +1 != self.mesh.dim:
            # +1 because it&#39;s a plane
            raise ValueError(&#34;dimensions of lists must equal number of dimensions&#34;)

        axis = None

        sizes = list(self.mesh.dm.getSizes())
        sizes.pop(axis)
        extent = np.reshape(self.mesh.extent, (-1,2))
        extent_bc = np.delete(extent, axis, axis=0)

        gcoords = []
        sizes = []
        for i in self.mesh.dim:
            if i != axis:
                coords = self.mesh.grid_coords[i]
                gcoords.append(coords)
                sizes.append(coords.size)

        ix = np.meshgrid(gcoords)
        
        # 0. divide wall into chunks based on the length of args
        # 1. find if proc contains bc mask
        # 2. map chunk to the bc



        bc_mask = self.mesh.bc[bc][&#39;mask&#39;]
        if bc_mask.any():
            pass



    def linear_solve(self, matrix=None, rhs=None):

        if matrix == None:
            matrix = self.mesh.construct_matrix()
        if rhs == None:
            rhs = self.mesh.construct_rhs()

        gvec = self.mesh.gvec
        lvec = self.mesh.lvec

        res = self.mesh.temperature
        # res._gdata.setArray(rhs._gdata)

        self.ksp.setOperators(matrix)
        self.ksp.solve(rhs._gdata, res._gdata)
        return res[:].copy()

    def linear_solve_ad(self, T, dT, matrix=None, rhs=None):
        &#34;&#34;&#34;
        If dT  = 0, adjoint=False : no need for this routine
        If dT != 0 and inside lithology, lith_size &gt; 0
        &#34;&#34;&#34;
        adjoint = np.array(False)
        lith_size = np.array(0.0)

        idxT = np.nonzero(dT != 0.0)[0]
        nT = idxT.any()
        comm.Allreduce([nT, MPI.BOOL], [adjoint, MPI.BOOL], op=MPI.LOR)
        if adjoint:
            if matrix == None:
                matrix = self.mesh.construct_matrix(in_place=True)
            if rhs == None:
                rhs = self.mesh.rhs
            rhs[:] = dT

            gvec = self.mesh.gvec
            lvec = self.mesh.lvec

            res = self.mesh.temperature
            res[:] = T

            # adjoint b vec
            db_ad = lvec.duplicate()

            gvec.setArray(rhs._gdata)
            self.ksp.solveTranspose(rhs._gdata, gvec)
            self.mesh.dm.globalToLocal(gvec, db_ad)

            # adjoint A mat
            dk_ad = np.zeros_like(T)

            matrix.scale(-1.0)
            # self.mesh.boundary_condition(&#39;maxZ&#39;, 0.0, flux=False) # not ND!!
            dT_ad = dT[:]
            kappa = np.zeros_like(T)
            
            nl = len(self.lithology_index)
            for i in range(0, nl):
                # find if there are nonzero dT that intersect a lithology
                idxM  = self.lithology_mask[i]
                idx_n = np.intersect1d(idxT, idxM)
                gnodes = self.ghost_weights[idx_n]
                local_size = np.array(float(idx_n.size)) - np.sum(1.0 - 1.0/gnodes) # ghost nodes
                comm.Allreduce([local_size, MPI.DOUBLE], [lith_size, MPI.DOUBLE], op=MPI.SUM)
                # print comm.rank, i, lith_size, idx_n.size

                if lith_size &gt; 0:
                    kappa.fill(0.0)
                    kappa[idxM] = 1.0
                    self.mesh.diffusivity[:] = kappa
                    dAdkl = self.mesh.construct_matrix(in_place=False, derivative=True)
                    dAdklT = dAdkl * res._gdata
                    gvec.setArray(dAdklT) # try make the solution somewhat close
                    self.ksp.solve(dAdklT, gvec)
                    self.mesh.dm.globalToLocal(gvec, lvec)

                    # need to call sum on the global vec
                    dk_local = (dT_ad*lvec.array)/lith_size
                    lvec.setArray(dk_local)
                    self.mesh.dm.localToGlobal(lvec, gvec)
                    gdot = gvec.sum()

                    if local_size &gt; 0:
                        # splatter inside vector
                        dk_ad[idx_n] += gdot

            dk_ad = self.mesh.sync(dk_ad)


            return dk_ad, db_ad.array
        else:
            return np.zeros_like(T), np.zeros_like(T)


    def gradient(self, f):
        &#34;&#34;&#34;
        Calculate the derivatives of f in each dimension.

        Parameters
        ----------
         f  : ndarray shape(n,)

        Returns
        -------
         grad_f : ndarray shape(3,n)

        &#34;&#34;&#34;
        grad = np.gradient(f.reshape(self.mesh.n), *self.grid_delta[::-1])
        return np.array(grad).reshape(self.mesh.dim, -1)

    def gradient_ad(self, df, f):
        inshape = [self.mesh.dim] + list(self.mesh.n)
        grad_ad = ad_grad(df.reshape(inshape), *self.grid_delta[::-1])
        return grad_ad.ravel()


    def heatflux(self, T, k):
        &#34;&#34;&#34;
        Calculate heat flux.

        Arguments
        ---------
         T  : ndarray shape(n,) temperature
         k  : ndarray shape(n,) conductivity

        Returns
        -------
         q  : ndarray shape(3,n), heatflux vectors
        &#34;&#34;&#34;
        return -k*self.gradient(T)

    def heatflux_ad(self, dq, q, T, k):

        dqddelT = -k
        dqdk = -self.gradient(T)

        ddelT = dqddelT*dq
        dk = dqdk*dq

        inshape = [self.mesh.dim] + list(self.mesh.n)

        dT = self.gradient_ad(ddelT, T)

        return dT.ravel(), dk.sum(axis=0)


    def add_perplex_table(self, TPtable):
        &#34;&#34;&#34;
        Add Perplex table.

        Performs checks to make sure all lithologies exist inside
        the table.
        &#34;&#34;&#34;
        from ..tools import PerplexTable
        if type(TPtable) is PerplexTable:
            for idx in self.lithology_index:
                if idx not in TPtable.table:
                    raise ValueError(&#39;{} not in TPtable&#39;.format(idx))
            self.TPtable = TPtable
        else:
            raise ValueError(&#39;TPtable is incorrect type&#39;)

    def lookup_velocity(self, T=None, P=None):
        &#34;&#34;&#34;
        Lookup velocity from VelocityTable object (vtable)

        Parameters
        ----------
         T  : temperature (optional)
           taken from active mesh variable if not given
         P  : pressure (optional)
           calculated from depth assuming a constant density of 2700 kg/m^3
        
        Returns
        -------
         table  : everything in the table for given nodes

        &#34;&#34;&#34;
        if T is None:
            T = self.mesh.temperature[:]
        if P is None:
            z = np.absolute(self.mesh.coords[:,-1])

            rho = 2700.0
            r = 6.38e6 # radius of the Earth
            M = 5.98e24 # mass of the Earth
            G = 6.673e-11 # gravitational constant
            g = G*M/(r-z)**2
            P = rho*g*z*1e-5

        nl = len(self.lithology_index)
        nf = self.TPtable.ncol

        # preallocate memory
        V = np.zeros((nf, self.mesh.nn))

        for i in range(0, nl):
            idx = self.lithology_mask[i]
            lith_idx = self.lithology_index[i]
            V[:,idx] = self.TPtable(T[idx], P[idx], lith_idx).T

        return V</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND"><code class="flex name class">
<span>class <span class="ident">InversionND</span></span>
<span>(</span><span>lithology, mesh, lithology_index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InversionND(object):

    def __init__(self, lithology, mesh, lithology_index=None, **kwargs):
        self.mesh = mesh

        # update internal mask structures
        self.update_lithology(lithology, lithology_index)


        # Custom linear / nearest-neighbour interpolator
        self.interp = RegularGridInterpolator(mesh.grid_coords[::-1],\
                                              np.zeros(mesh.n),\
                                              bounds_error=False, fill_value=np.nan)

        self.ndinterp = KDTreeInterpolator(mesh.coords, np.zeros(mesh.nn),\
                                           bounds_error=False, fill_value=0.0)

        # Get weights for ghost points
        mesh.lvec.set(1.0)
        mesh.gvec.set(0.0)
        mesh.dm.localToGlobal(mesh.lvec, mesh.gvec, addv=True)
        mesh.dm.globalToLocal(mesh.gvec, mesh.lvec)
        self.ghost_weights = np.rint(mesh.lvec.array)


        # We assume uniform grid spacing for now
        delta = []
        for i in range(0, mesh.dim):
            dx = np.diff(mesh.grid_coords[i])
            delta.append(dx.mean())
        self.grid_delta = delta


        # objective function dictionaries
        self.observation = {}
        self.prior = {}


        # Initialise linear solver
        self.ksp = self._initialise_ksp(**kwargs)

        # these should be depreciated soon
        self.temperature = self.mesh.gvec.duplicate()
        self._temperature = self.mesh.gvec.duplicate()
        self.iii = 0


    def update_lithology(self, new_lithology, lithology_index=None):
        &#34;&#34;&#34;
        Update the configuration of lithologies.

        Internal mask structures are updated to reflect the change in
        lithology configuration.

        Arguments
        ---------
         new_lithology   : field on the mesh with integers indicating
            : the position of particular lithologies
         lithology_index : array corresponding to the total number of
            : integers in new_lithology
        
        Notes
        -----
         lithology_index is determined from the min/max of elements
         in new_lithology if lithology_index=None
        &#34;&#34;&#34;

        new_lithology = np.array(new_lithology).ravel()

        # sync across processors
        new_lithology = self.mesh.sync(new_lithology)
        new_lithology = new_lithology.astype(np.int)

        if type(lithology_index) == type(None):
            # query global vector for minx/max
            iloc, lith_min = self.mesh.gvec.min()
            iloc, lith_max = self.mesh.gvec.max()

            # create lithology index
            lithology_index = np.arange(int(lith_min), int(lith_max)+1)


        nl = len(lithology_index)
        lithology_mask = [i for i in range(nl)]

        # create lithology mask
        for i, index in enumerate(lithology_index):
            lithology_mask[i] = np.nonzero(new_lithology == index)[0]

        self.lithology_mask = lithology_mask
        self.lithology_index = lithology_index
        self._lithology = new_lithology

        return

    @property
    def lithology(self):
        return self._lithology
    @lithology.setter
    def lithology(self, new_lithology):
        self.update_lithology(new_lithology)


    def _initialise_ksp(self, matrix=None, atol=1e-10, rtol=1e-50, **kwargs):
        &#34;&#34;&#34;
        Initialise linear solver object
        &#34;&#34;&#34;
        if matrix is None:
            matrix = self.mesh.mat

        solver = kwargs.pop(&#39;solver&#39;, &#39;gmres&#39;)
        precon = kwargs.pop(&#39;pc&#39;, None)

        ksp = PETSc.KSP().create(comm)
        ksp.setType(solver)
        ksp.setOperators(matrix)
        ksp.setTolerances(atol, rtol)
        if precon is not None:
            pc = ksp.getPC()
            pc.setType(precon)
        ksp.setFromOptions()
        return ksp

    def get_boundary_conditions(self):
        &#34;&#34;&#34;
        Retrieve the boundary conditions so they can be restored.
        This is only useful in the adjoint linear solve where we must assert
        Dirichlet BCs (I think)

        order is [minX, maxX, minY, maxY, minZ, maxZ]

        Returns
        -------
         bc_vals : values at the boundary conditions
         bc_flux : whether it is a Neumann boundary condition

        &#34;&#34;&#34;
        dim = self.mesh.dim
        bc_vals = np.empty(dim*2)
        bc_flux = np.empty(dim*2, dtype=bool)

        wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

        for i in range(0, dim):
            w0, w1 = wall[i]
            i0, i1 = i*2, i*2+1

            bc_vals[i0] = self.mesh.bc[w0][&#34;val&#34;]
            bc_flux[i0] = self.mesh.bc[w0][&#34;flux&#34;]

            bc_vals[i1] = self.mesh.bc[w1][&#34;val&#34;]
            bc_flux[i1] = self.mesh.bc[w1][&#34;flux&#34;]

        return bc_vals, bc_flux


    def set_boundary_conditions(self, bc_vals, bc_flux):
        &#34;&#34;&#34;
        Set the boundary conditions easily using two vectors
        order is [minX, maxX, minY, maxY, minZ, maxZ]

        Parameters
        -------
         bc_vals : values at the boundary conditions
         bc_flux : whether it is a Neumann boundary condition

        &#34;&#34;&#34;
        dim = self.mesh.dim
        if len(bc_vals) != len(bc_flux) or len(bc_vals) != dim*2:
            raise ValueError(&#34;Input vectors should be of size {}&#34;.format(dim*2))

        wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

        for i in range(0, dim):
            w0, w1 = wall[i]
            i0, i1 = i*2, i*2+1

            self.mesh.bc[w0][&#34;val&#34;]  = bc_vals[i0]
            self.mesh.bc[w0][&#34;flux&#34;] = bc_flux[i0]

            self.mesh.bc[w1][&#34;val&#34;]  = bc_vals[i1]
            self.mesh.bc[w1][&#34;flux&#34;] = bc_flux[i1]


    def add_observation(self, **kwargs):
        &#34;&#34;&#34;
        Add an observation to the Inversion routine.
        These will automatically be called when the objective function is called
        and will handle interpolation.

        &#34;&#34;&#34;
        interp = self.interp
        interp.values = self.ghost_weights.reshape(self.mesh.n)

        for arg in kwargs:
            obs = kwargs[arg]
            if type(obs) is not InvObservation:
                raise TypeError(&#34;Need to pass {} instead of {}&#34;.format(InvObservation,type(obs)))

            # add interpolation information to obs
            w = interp(obs.coords[:,::-1])
            w = 1.0/np.floor(w + 1e-12)
            offproc = np.isnan(w)
            w[offproc] = 0.0 # these are weighted with zeros
            obs.w = w # careful with 2x ghost nodes+

            # store in dictionary
            self.observation[arg] = obs


    def add_prior(self, **kwargs):
        &#34;&#34;&#34;
        Add a prior to the Inversion routine
        &#34;&#34;&#34;

        for arg in kwargs:
            prior = kwargs[arg]
            if type(prior) is not InvPrior:
                raise TypeError(&#34;Need to pass {} instead of {}&#34;.format(InvPrior, type(prior)))

            prior.w = 1.0

            # store in dictionary
            self.prior[arg] = prior


    def objective_routine(self, **kwargs):
        &#34;&#34;&#34;
        This always comes at the end of the forward model (beginning of the adjoint)
        so we can safely roll interpolation, cost into one method.

        Argument is a field if it is an observation - so that we can interpolate it.
        &#34;&#34;&#34;

        # ensure an objective function is provided
        # if self.objective_function is None:
            # raise ValueError(&#34;Pass an objective function&#34;)

        c = np.array(0.0) # local prior values same as global
        c_obs = np.array(0.0) # obs have to be summed over all procs
        c_all = np.array(0.0) # sum of all obs

        for arg in kwargs:
            val = kwargs[arg]
            if arg in self.prior:
                prior = self.prior[arg]

                if prior.cov is None:
                    c += self.objective_function(val, prior.v, prior.dv)
                else:
                    c += self.objective_function_lstsq(val, prior.v, prior.cov)
            elif arg in self.observation:
                obs = self.observation[arg]

                # interpolation
                ival = self.interpolate(val, obs.coords)

                # weighting for ghost nodes
                if obs.cov is None:
                    c_obs += self.objective_function(ival*obs.w, obs.v*obs.w, obs.dv)
                else:
                    c_obs += self.objective_function_lstsq(ival*obs.w, obs.v*obs.w, obs.cov)



        comm.Allreduce([c_obs, MPI.DOUBLE], [c_all, MPI.DOUBLE], op=MPI.SUM)
        c += c_all
        return c

    def objective_routine_ad(self, **kwargs):

        dcdv = 0.0

        for arg in kwargs:
            val = kwargs[arg]
            if arg in self.prior:
                prior = self.prior[arg]
                if prior.cov is None:
                    dcdv = self.objective_function_ad(val, prior.v, prior.dv)
                else:
                    dcdv = self.objective_function_lstsq_ad(val, prior.v, prior.cov)

            elif arg in self.observation:
                obs = self.observation[arg]

                ival = self.interpolate(val, obs.coords)


                if obs.cov is None:
                    dcdinterp = self.objective_function_ad(ival, obs.v, obs.dv)
                else:
                    dcdinterp = self.objective_function_lstsq_ad(ival*obs.w, obs.v*obs.w, obs.cov)

                # interpolation
                dcdv = self.interpolate_ad(dcdinterp, val, obs.coords)
                # print arg, np.shape(val), np.shape(ival), np.shape(dcdv)

                # sync
                dcdv = self.mesh.sync(dcdv)
            else:
                dcdv = np.zeros_like(val)

        return dcdv


    def create_covariance_matrix(self, sigma_x0, width=1, indexing=&#39;xy&#39;, fn=None, *args):
        &#34;&#34;&#34;
        Create a covariance matrix assuming some function for variables on the mesh
        By default this is Gaussian.

        Arguments
        ---------
         sigma_x0 : uncertainty values to insert into matrix
         width    : width of stencil for matrix (int)
            i.e. extended number of neighbours for each node
         indexing : use the xy coordinates of the mesh nodes or indices
            set to &#39;xy&#39; or &#39;ij&#39;
         fn       : function to apply (default is Gaussian)
         *args    : input arguments to pass to fn

        Returns
        -------
            mat : covariance matrix
        &#34;&#34;&#34;

        def gaussian_fn(sigma_x0, dist, length_scale):
            return sigma_x0**2 * np.exp(-dist**2/(2*length_scale**2))

        if type(fn) == type(None):
            fn = gaussian_fn

        nodes = self.mesh.nodes
        nn = self.mesh.nn
        n = self.mesh.n
        dim = self.mesh.dim

        if indexing == &#34;xy&#34;:
            coords = self.mesh.coords
        elif indexing == &#34;ij&#34;:
            ic = []
            for i in range(dim):
                ic.append( np.arange(n[i]) )
            cij = np.meshgrid(*ic, indexing=&#34;ij&#34;)

            for i in range(dim):
                cij[i] = cij[i].ravel()
            coords = np.column_stack(cij)

        # setup new stencil
        stencil_width = 2*self.mesh.dim*width + 1
        rows = np.empty((stencil_width, self.mesh.nn), dtype=PETSc.IntType)
        cols = np.empty((stencil_width, self.mesh.nn), dtype=PETSc.IntType)
        vals = np.empty((stencil_width, self.mesh.nn))
        index = np.pad(nodes.reshape(n), width, &#39;constant&#39;, constant_values=-1)
        sigma = np.pad(sigma_x0.reshape(n), width, &#39;constant&#39;, constant_values=0)

        closure = []
        for w in range(width, 0, -1):
            closure_array = self.mesh._get_closure_array(dim, w, width)
            closure.extend(closure_array[:-1])
        closure.append(closure_array[-1]) # centre node at last

        # create closure object
        closure = self.mesh._create_closure_object(closure, width)


        for i in range(0, stencil_width):
            obj = closure[i]

            rows[i] = nodes
            cols[i] = index[obj].ravel()

            distance = np.linalg.norm(coords[cols[i]] - coords, axis=1)
            vals[i] = fn(sigma[obj].ravel(), distance, *args)

        vals[cols &lt; 0] = 0.0
        vals[-1] = 0.0

        row = rows.ravel()
        col = cols.ravel()
        val = vals.ravel()

        # mask off-grid entries and sum duplicates
        mask = col &gt;= 0
        row, col, val = sum_duplicates(row[mask], col[mask], val[mask])

        nnz = np.bincount(row)
        indptr = np.insert(np.cumsum(nnz),0,0)

        nnz = (stencil_width, dim*2)
        mat = self.mesh._initialise_matrix(nnz=nnz)
        mat.assemblyBegin()
        mat.setValuesLocalCSR(indptr.astype(PETSc.IntType), col, val)
        mat.assemblyEnd()

        # set diagonal vector
        lvec = self.mesh.lvec
        gvec = self.mesh.gvec
        lvec.setArray(sigma_x0**2)
        self.mesh.dm.localToGlobal(lvec, gvec)
        mat.setDiagonal(gvec)
        return mat


    def create_covariance_matrix_kdtree(self, sigma_x0, width=1, indexing=&#39;xy&#39;, fn=None, *args):
        &#34;&#34;&#34;
        Create a covariance matrix assuming some function for variables on the mesh.
        By default this is Gaussian.

        This uses a KDTree to determine distance between nodes, rather than the
        matrix stencil indexing used by create_covariance_matrix
        

        Arguments
        ---------
         sigma_x0 : uncertainty values to insert into matrix
         width    : width of stencil for matrix (int)
            i.e. extended number of neighbours for each node
         indexing : use the xy coordinates of the mesh nodes or indices
            set to &#39;xy&#39; or &#39;ij&#39;
         fn       : function to apply (default is Gaussian)
         *args    : input arguments to pass to fn

        Returns
        -------
            mat : covariance matrix
        &#34;&#34;&#34;

        def gaussian_fn(sigma_x0, dist, length_scale):
            return sigma_x0**2 * np.exp(-dist**2/(2*length_scale**2))

        if type(fn) == type(None):
            fn = gaussian_fn

        nodes = self.mesh.nodes
        nn = self.mesh.nn
        n = self.mesh.n
        dim = self.mesh.dim

        if indexing == &#34;xy&#34;:
            coords = self.mesh.coords
            tree = self.ndinterp.tree
        elif indexing == &#34;ij&#34;:
            from scipy.spatial import cKDTree

            ic = []
            for i in range(dim):
                ic.append( np.arange(n[i]) )
            cij = np.meshgrid(*ic, indexing=&#34;ij&#34;)

            for i in range(dim):
                cij[i] = cij[i].ravel()
            coords = np.column_stack(cij)
            tree = cKDTree(coords)


        # find distance between coords and centroid
        dist = np.linalg.norm(coords - coords.mean(axis=0), axis=1)
        nnz = int(1.5*(dist &lt;= max_dist).sum())

        mat = self.mesh._initialise_matrix(nnz=(nnz,1))
        mat.assemblyBegin()

        for i in range(0, nn):
            idx = tree.query_ball_point(coords[i], max_dist)
            dist = np.linalg.norm(coords[i] - coords[idx], axis=1)
            
            row = i
            col = idx
            val = fn(sigma[idx], dist, *args, **kwargs)
            
            mat.setValues(row, col, val)

        mat.assemblyEnd()
        return mat


    def interpolate(self, field, xi, method=&#34;nearest&#34;):
        self.ndinterp.values = field #.reshape(self.mesh.n)
        return self.ndinterp(xi, method=method)

    def interpolate_ad(self, dxi, field, xi, method=&#34;nearest&#34;):
        self.ndinterp.values = field #.reshape(self.mesh.n)
        return self.ndinterp.adjoint(xi, dxi, method=method) #.ravel()

    def in_bounds(self, xi):
        &#34;&#34;&#34;
        Find if coordinates are inside the local processor bounds
        &#34;&#34;&#34;
        idx, d, bounds = self.ndinterp._find_indices(xi)
        return bounds


    def objective_function(self, x, x0, sigma_x0):
        return np.sum(0.5*(x - x0)**2/sigma_x0**2)

    def objective_function_ad(self, x, x0, sigma_x0):
        return 0.5*(2.0*x - 2.0*x0)/sigma_x0**2


    def objective_function_lstsq(self, x, x0, cov):
        &#34;&#34;&#34;
        Nonlinear least squares objective function
        &#34;&#34;&#34;
        ksp = self._initialise_ksp(cov, pc=&#39;lu&#39;)
        misfit = np.array(x - x0)
        lhs, rhs = cov.createVecs()
        rhs.set(0.0)
        lindices = np.arange(0, misfit.size, dtype=PETSc.IntType)
        rhs.setValues(lindices, misfit, PETSc.InsertMode.ADD_VALUES)
        rhs.assemble()
        ksp.solve(rhs, lhs)
        sol = rhs*lhs
        sol.scale(0.5)

        ksp.destroy()
        lhs.destroy()
        rhs.destroy()

        return sol.sum()/comm.size

    def objective_function_lstsq_ad(self, x, x0, cov):
        &#34;&#34;&#34;
        Adjoint of the nonlinear least squares objective function
        &#34;&#34;&#34;
        ksp = self._initialise_ksp(cov, pc=&#39;lu&#39;)

        misfit = np.array(x - x0)
        lhs, rhs = cov.createVecs()
        rhs.set(0.0)
        lindices = np.arange(0, misfit.size, dtype=PETSc.IntType)
        rhs.setValues(lindices, misfit, PETSc.InsertMode.ADD_VALUES)
        rhs.assemble()
        ksp.solve(rhs, lhs)

        toall, allvec = PETSc.Scatter.toAll(lhs)
        toall.scatter(lhs, allvec, PETSc.InsertMode.INSERT)

        ksp.destroy()
        lhs.destroy()
        return allvec.array


    def map(self, *args):
        &#34;&#34;&#34;
        Requires a tuple of vectors corresponding to an inversion variable
        these are mapped to the mesh.

        tuple(vec1, vec2, vecN) --&gt; tuple(field1, field2, fieldN)
        &#34;&#34;&#34;

        nf = len(args)
        nl = len(self.lithology_index)

        # preallocate local memory
        mesh_variables = np.zeros((nf, self.mesh.nn))

        # unpack vector to field
        for i in range(0, nl):
            idx = self.lithology_mask[i]
            for f in range(nf):
                mesh_variables[f,idx] = args[f][i]

        # sync fields across processors
        for f in range(nf):
            mesh_variables[f] = self.mesh.sync(mesh_variables[f])

        return list(mesh_variables)

    def map_ad(self, *args):
        &#34;&#34;&#34;
        Map mesh variables back to the list
        &#34;&#34;&#34;
        
        nf = len(args)
        nl = len(self.lithology_index)

        # sync fields across processors
        mesh_variables = np.zeros((nf, self.mesh.nn))
        for f in range(nf):
            mesh_variables[f] = self.mesh.sync(args[f])

        lith_variables = np.zeros((nf, self.lithology_index.size))
        all_lith_variables = np.zeros_like(lith_variables)

        for i in range(0, nl):
            idx = self.lithology_mask[i]
            for f in range(nf):
                lith_variables[f,i] += (mesh_variables[f]/self.ghost_weights)[idx].sum()

        comm.Allreduce([lith_variables, MPI.DOUBLE], [all_lith_variables, MPI.DOUBLE], op=MPI.SUM)

        return list(all_lith_variables)


    def create_wall_map(self, wall, *args):
        coords = self.mesh.coords
        dim = self.mesh.dim

        bbox = self.mesh.dm.getBoundingBox()
        sizes = self.mesh.dm.getSizes()

        # Setup boundary dictionary
        bc = dict()

        wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

        for i in range(0, dim):
            w0, w1 = wall[i]
            c0, c1 = bbox[i]
            m0, m1 = coords[:,i] == c0, coords[:,i] == c1

        
        self.boundary_index = boundary_index


    def map_wall(self, wall, *args):
        &#34;&#34;&#34;
        Map lists of arguments to a boundary wall


        &#34;&#34;&#34;

        if wall not in self.mesh.bc:
            raise ValueError(&#34;wall must be one of {}&#34;.format(self.mesh.bc.keys()))
        if len(args) +1 != self.mesh.dim:
            # +1 because it&#39;s a plane
            raise ValueError(&#34;dimensions of lists must equal number of dimensions&#34;)

        axis = None

        sizes = list(self.mesh.dm.getSizes())
        sizes.pop(axis)
        extent = np.reshape(self.mesh.extent, (-1,2))
        extent_bc = np.delete(extent, axis, axis=0)

        gcoords = []
        sizes = []
        for i in self.mesh.dim:
            if i != axis:
                coords = self.mesh.grid_coords[i]
                gcoords.append(coords)
                sizes.append(coords.size)

        ix = np.meshgrid(gcoords)
        
        # 0. divide wall into chunks based on the length of args
        # 1. find if proc contains bc mask
        # 2. map chunk to the bc



        bc_mask = self.mesh.bc[bc][&#39;mask&#39;]
        if bc_mask.any():
            pass



    def linear_solve(self, matrix=None, rhs=None):

        if matrix == None:
            matrix = self.mesh.construct_matrix()
        if rhs == None:
            rhs = self.mesh.construct_rhs()

        gvec = self.mesh.gvec
        lvec = self.mesh.lvec

        res = self.mesh.temperature
        # res._gdata.setArray(rhs._gdata)

        self.ksp.setOperators(matrix)
        self.ksp.solve(rhs._gdata, res._gdata)
        return res[:].copy()

    def linear_solve_ad(self, T, dT, matrix=None, rhs=None):
        &#34;&#34;&#34;
        If dT  = 0, adjoint=False : no need for this routine
        If dT != 0 and inside lithology, lith_size &gt; 0
        &#34;&#34;&#34;
        adjoint = np.array(False)
        lith_size = np.array(0.0)

        idxT = np.nonzero(dT != 0.0)[0]
        nT = idxT.any()
        comm.Allreduce([nT, MPI.BOOL], [adjoint, MPI.BOOL], op=MPI.LOR)
        if adjoint:
            if matrix == None:
                matrix = self.mesh.construct_matrix(in_place=True)
            if rhs == None:
                rhs = self.mesh.rhs
            rhs[:] = dT

            gvec = self.mesh.gvec
            lvec = self.mesh.lvec

            res = self.mesh.temperature
            res[:] = T

            # adjoint b vec
            db_ad = lvec.duplicate()

            gvec.setArray(rhs._gdata)
            self.ksp.solveTranspose(rhs._gdata, gvec)
            self.mesh.dm.globalToLocal(gvec, db_ad)

            # adjoint A mat
            dk_ad = np.zeros_like(T)

            matrix.scale(-1.0)
            # self.mesh.boundary_condition(&#39;maxZ&#39;, 0.0, flux=False) # not ND!!
            dT_ad = dT[:]
            kappa = np.zeros_like(T)
            
            nl = len(self.lithology_index)
            for i in range(0, nl):
                # find if there are nonzero dT that intersect a lithology
                idxM  = self.lithology_mask[i]
                idx_n = np.intersect1d(idxT, idxM)
                gnodes = self.ghost_weights[idx_n]
                local_size = np.array(float(idx_n.size)) - np.sum(1.0 - 1.0/gnodes) # ghost nodes
                comm.Allreduce([local_size, MPI.DOUBLE], [lith_size, MPI.DOUBLE], op=MPI.SUM)
                # print comm.rank, i, lith_size, idx_n.size

                if lith_size &gt; 0:
                    kappa.fill(0.0)
                    kappa[idxM] = 1.0
                    self.mesh.diffusivity[:] = kappa
                    dAdkl = self.mesh.construct_matrix(in_place=False, derivative=True)
                    dAdklT = dAdkl * res._gdata
                    gvec.setArray(dAdklT) # try make the solution somewhat close
                    self.ksp.solve(dAdklT, gvec)
                    self.mesh.dm.globalToLocal(gvec, lvec)

                    # need to call sum on the global vec
                    dk_local = (dT_ad*lvec.array)/lith_size
                    lvec.setArray(dk_local)
                    self.mesh.dm.localToGlobal(lvec, gvec)
                    gdot = gvec.sum()

                    if local_size &gt; 0:
                        # splatter inside vector
                        dk_ad[idx_n] += gdot

            dk_ad = self.mesh.sync(dk_ad)


            return dk_ad, db_ad.array
        else:
            return np.zeros_like(T), np.zeros_like(T)


    def gradient(self, f):
        &#34;&#34;&#34;
        Calculate the derivatives of f in each dimension.

        Parameters
        ----------
         f  : ndarray shape(n,)

        Returns
        -------
         grad_f : ndarray shape(3,n)

        &#34;&#34;&#34;
        grad = np.gradient(f.reshape(self.mesh.n), *self.grid_delta[::-1])
        return np.array(grad).reshape(self.mesh.dim, -1)

    def gradient_ad(self, df, f):
        inshape = [self.mesh.dim] + list(self.mesh.n)
        grad_ad = ad_grad(df.reshape(inshape), *self.grid_delta[::-1])
        return grad_ad.ravel()


    def heatflux(self, T, k):
        &#34;&#34;&#34;
        Calculate heat flux.

        Arguments
        ---------
         T  : ndarray shape(n,) temperature
         k  : ndarray shape(n,) conductivity

        Returns
        -------
         q  : ndarray shape(3,n), heatflux vectors
        &#34;&#34;&#34;
        return -k*self.gradient(T)

    def heatflux_ad(self, dq, q, T, k):

        dqddelT = -k
        dqdk = -self.gradient(T)

        ddelT = dqddelT*dq
        dk = dqdk*dq

        inshape = [self.mesh.dim] + list(self.mesh.n)

        dT = self.gradient_ad(ddelT, T)

        return dT.ravel(), dk.sum(axis=0)


    def add_perplex_table(self, TPtable):
        &#34;&#34;&#34;
        Add Perplex table.

        Performs checks to make sure all lithologies exist inside
        the table.
        &#34;&#34;&#34;
        from ..tools import PerplexTable
        if type(TPtable) is PerplexTable:
            for idx in self.lithology_index:
                if idx not in TPtable.table:
                    raise ValueError(&#39;{} not in TPtable&#39;.format(idx))
            self.TPtable = TPtable
        else:
            raise ValueError(&#39;TPtable is incorrect type&#39;)

    def lookup_velocity(self, T=None, P=None):
        &#34;&#34;&#34;
        Lookup velocity from VelocityTable object (vtable)

        Parameters
        ----------
         T  : temperature (optional)
           taken from active mesh variable if not given
         P  : pressure (optional)
           calculated from depth assuming a constant density of 2700 kg/m^3
        
        Returns
        -------
         table  : everything in the table for given nodes

        &#34;&#34;&#34;
        if T is None:
            T = self.mesh.temperature[:]
        if P is None:
            z = np.absolute(self.mesh.coords[:,-1])

            rho = 2700.0
            r = 6.38e6 # radius of the Earth
            M = 5.98e24 # mass of the Earth
            G = 6.673e-11 # gravitational constant
            g = G*M/(r-z)**2
            P = rho*g*z*1e-5

        nl = len(self.lithology_index)
        nf = self.TPtable.ncol

        # preallocate memory
        V = np.zeros((nf, self.mesh.nn))

        for i in range(0, nl):
            idx = self.lithology_mask[i]
            lith_idx = self.lithology_index[i]
            V[:,idx] = self.TPtable(T[idx], P[idx], lith_idx).T

        return V</code></pre>
</details>
<h3>Instance variables</h3>
<dl>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.lithology"><code class="name">var <span class="ident">lithology</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def lithology(self):
    return self._lithology</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.add_observation"><code class="name flex">
<span>def <span class="ident">add_observation</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Add an observation to the Inversion routine.
These will automatically be called when the objective function is called
and will handle interpolation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_observation(self, **kwargs):
    &#34;&#34;&#34;
    Add an observation to the Inversion routine.
    These will automatically be called when the objective function is called
    and will handle interpolation.

    &#34;&#34;&#34;
    interp = self.interp
    interp.values = self.ghost_weights.reshape(self.mesh.n)

    for arg in kwargs:
        obs = kwargs[arg]
        if type(obs) is not InvObservation:
            raise TypeError(&#34;Need to pass {} instead of {}&#34;.format(InvObservation,type(obs)))

        # add interpolation information to obs
        w = interp(obs.coords[:,::-1])
        w = 1.0/np.floor(w + 1e-12)
        offproc = np.isnan(w)
        w[offproc] = 0.0 # these are weighted with zeros
        obs.w = w # careful with 2x ghost nodes+

        # store in dictionary
        self.observation[arg] = obs</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.add_perplex_table"><code class="name flex">
<span>def <span class="ident">add_perplex_table</span></span>(<span>self, TPtable)</span>
</code></dt>
<dd>
<div class="desc"><p>Add Perplex table.</p>
<p>Performs checks to make sure all lithologies exist inside
the table.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_perplex_table(self, TPtable):
    &#34;&#34;&#34;
    Add Perplex table.

    Performs checks to make sure all lithologies exist inside
    the table.
    &#34;&#34;&#34;
    from ..tools import PerplexTable
    if type(TPtable) is PerplexTable:
        for idx in self.lithology_index:
            if idx not in TPtable.table:
                raise ValueError(&#39;{} not in TPtable&#39;.format(idx))
        self.TPtable = TPtable
    else:
        raise ValueError(&#39;TPtable is incorrect type&#39;)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.add_prior"><code class="name flex">
<span>def <span class="ident">add_prior</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Add a prior to the Inversion routine</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_prior(self, **kwargs):
    &#34;&#34;&#34;
    Add a prior to the Inversion routine
    &#34;&#34;&#34;

    for arg in kwargs:
        prior = kwargs[arg]
        if type(prior) is not InvPrior:
            raise TypeError(&#34;Need to pass {} instead of {}&#34;.format(InvPrior, type(prior)))

        prior.w = 1.0

        # store in dictionary
        self.prior[arg] = prior</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.create_covariance_matrix"><code class="name flex">
<span>def <span class="ident">create_covariance_matrix</span></span>(<span>self, sigma_x0, width=1, indexing='xy', fn=None, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a covariance matrix assuming some function for variables on the mesh
By default this is Gaussian.</p>
<h2 id="arguments">Arguments</h2>
<p>sigma_x0 : uncertainty values to insert into matrix
width
: width of stencil for matrix (int)
i.e. extended number of neighbours for each node
indexing : use the xy coordinates of the mesh nodes or indices
set to 'xy' or 'ij'
fn
: function to apply (default is Gaussian)
*args
: input arguments to pass to fn</p>
<h2 id="returns">Returns</h2>
<pre><code>mat : covariance matrix
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_covariance_matrix(self, sigma_x0, width=1, indexing=&#39;xy&#39;, fn=None, *args):
    &#34;&#34;&#34;
    Create a covariance matrix assuming some function for variables on the mesh
    By default this is Gaussian.

    Arguments
    ---------
     sigma_x0 : uncertainty values to insert into matrix
     width    : width of stencil for matrix (int)
        i.e. extended number of neighbours for each node
     indexing : use the xy coordinates of the mesh nodes or indices
        set to &#39;xy&#39; or &#39;ij&#39;
     fn       : function to apply (default is Gaussian)
     *args    : input arguments to pass to fn

    Returns
    -------
        mat : covariance matrix
    &#34;&#34;&#34;

    def gaussian_fn(sigma_x0, dist, length_scale):
        return sigma_x0**2 * np.exp(-dist**2/(2*length_scale**2))

    if type(fn) == type(None):
        fn = gaussian_fn

    nodes = self.mesh.nodes
    nn = self.mesh.nn
    n = self.mesh.n
    dim = self.mesh.dim

    if indexing == &#34;xy&#34;:
        coords = self.mesh.coords
    elif indexing == &#34;ij&#34;:
        ic = []
        for i in range(dim):
            ic.append( np.arange(n[i]) )
        cij = np.meshgrid(*ic, indexing=&#34;ij&#34;)

        for i in range(dim):
            cij[i] = cij[i].ravel()
        coords = np.column_stack(cij)

    # setup new stencil
    stencil_width = 2*self.mesh.dim*width + 1
    rows = np.empty((stencil_width, self.mesh.nn), dtype=PETSc.IntType)
    cols = np.empty((stencil_width, self.mesh.nn), dtype=PETSc.IntType)
    vals = np.empty((stencil_width, self.mesh.nn))
    index = np.pad(nodes.reshape(n), width, &#39;constant&#39;, constant_values=-1)
    sigma = np.pad(sigma_x0.reshape(n), width, &#39;constant&#39;, constant_values=0)

    closure = []
    for w in range(width, 0, -1):
        closure_array = self.mesh._get_closure_array(dim, w, width)
        closure.extend(closure_array[:-1])
    closure.append(closure_array[-1]) # centre node at last

    # create closure object
    closure = self.mesh._create_closure_object(closure, width)


    for i in range(0, stencil_width):
        obj = closure[i]

        rows[i] = nodes
        cols[i] = index[obj].ravel()

        distance = np.linalg.norm(coords[cols[i]] - coords, axis=1)
        vals[i] = fn(sigma[obj].ravel(), distance, *args)

    vals[cols &lt; 0] = 0.0
    vals[-1] = 0.0

    row = rows.ravel()
    col = cols.ravel()
    val = vals.ravel()

    # mask off-grid entries and sum duplicates
    mask = col &gt;= 0
    row, col, val = sum_duplicates(row[mask], col[mask], val[mask])

    nnz = np.bincount(row)
    indptr = np.insert(np.cumsum(nnz),0,0)

    nnz = (stencil_width, dim*2)
    mat = self.mesh._initialise_matrix(nnz=nnz)
    mat.assemblyBegin()
    mat.setValuesLocalCSR(indptr.astype(PETSc.IntType), col, val)
    mat.assemblyEnd()

    # set diagonal vector
    lvec = self.mesh.lvec
    gvec = self.mesh.gvec
    lvec.setArray(sigma_x0**2)
    self.mesh.dm.localToGlobal(lvec, gvec)
    mat.setDiagonal(gvec)
    return mat</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.create_covariance_matrix_kdtree"><code class="name flex">
<span>def <span class="ident">create_covariance_matrix_kdtree</span></span>(<span>self, sigma_x0, width=1, indexing='xy', fn=None, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a covariance matrix assuming some function for variables on the mesh.
By default this is Gaussian.</p>
<p>This uses a KDTree to determine distance between nodes, rather than the
matrix stencil indexing used by create_covariance_matrix</p>
<h2 id="arguments">Arguments</h2>
<p>sigma_x0 : uncertainty values to insert into matrix
width
: width of stencil for matrix (int)
i.e. extended number of neighbours for each node
indexing : use the xy coordinates of the mesh nodes or indices
set to 'xy' or 'ij'
fn
: function to apply (default is Gaussian)
*args
: input arguments to pass to fn</p>
<h2 id="returns">Returns</h2>
<pre><code>mat : covariance matrix
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_covariance_matrix_kdtree(self, sigma_x0, width=1, indexing=&#39;xy&#39;, fn=None, *args):
    &#34;&#34;&#34;
    Create a covariance matrix assuming some function for variables on the mesh.
    By default this is Gaussian.

    This uses a KDTree to determine distance between nodes, rather than the
    matrix stencil indexing used by create_covariance_matrix
    

    Arguments
    ---------
     sigma_x0 : uncertainty values to insert into matrix
     width    : width of stencil for matrix (int)
        i.e. extended number of neighbours for each node
     indexing : use the xy coordinates of the mesh nodes or indices
        set to &#39;xy&#39; or &#39;ij&#39;
     fn       : function to apply (default is Gaussian)
     *args    : input arguments to pass to fn

    Returns
    -------
        mat : covariance matrix
    &#34;&#34;&#34;

    def gaussian_fn(sigma_x0, dist, length_scale):
        return sigma_x0**2 * np.exp(-dist**2/(2*length_scale**2))

    if type(fn) == type(None):
        fn = gaussian_fn

    nodes = self.mesh.nodes
    nn = self.mesh.nn
    n = self.mesh.n
    dim = self.mesh.dim

    if indexing == &#34;xy&#34;:
        coords = self.mesh.coords
        tree = self.ndinterp.tree
    elif indexing == &#34;ij&#34;:
        from scipy.spatial import cKDTree

        ic = []
        for i in range(dim):
            ic.append( np.arange(n[i]) )
        cij = np.meshgrid(*ic, indexing=&#34;ij&#34;)

        for i in range(dim):
            cij[i] = cij[i].ravel()
        coords = np.column_stack(cij)
        tree = cKDTree(coords)


    # find distance between coords and centroid
    dist = np.linalg.norm(coords - coords.mean(axis=0), axis=1)
    nnz = int(1.5*(dist &lt;= max_dist).sum())

    mat = self.mesh._initialise_matrix(nnz=(nnz,1))
    mat.assemblyBegin()

    for i in range(0, nn):
        idx = tree.query_ball_point(coords[i], max_dist)
        dist = np.linalg.norm(coords[i] - coords[idx], axis=1)
        
        row = i
        col = idx
        val = fn(sigma[idx], dist, *args, **kwargs)
        
        mat.setValues(row, col, val)

    mat.assemblyEnd()
    return mat</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.create_wall_map"><code class="name flex">
<span>def <span class="ident">create_wall_map</span></span>(<span>self, wall, *args)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_wall_map(self, wall, *args):
    coords = self.mesh.coords
    dim = self.mesh.dim

    bbox = self.mesh.dm.getBoundingBox()
    sizes = self.mesh.dm.getSizes()

    # Setup boundary dictionary
    bc = dict()

    wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

    for i in range(0, dim):
        w0, w1 = wall[i]
        c0, c1 = bbox[i]
        m0, m1 = coords[:,i] == c0, coords[:,i] == c1

    
    self.boundary_index = boundary_index</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.get_boundary_conditions"><code class="name flex">
<span>def <span class="ident">get_boundary_conditions</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Retrieve the boundary conditions so they can be restored.
This is only useful in the adjoint linear solve where we must assert
Dirichlet BCs (I think)</p>
<p>order is [minX, maxX, minY, maxY, minZ, maxZ]</p>
<h2 id="returns">Returns</h2>
<p>bc_vals : values at the boundary conditions
bc_flux : whether it is a Neumann boundary condition</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_boundary_conditions(self):
    &#34;&#34;&#34;
    Retrieve the boundary conditions so they can be restored.
    This is only useful in the adjoint linear solve where we must assert
    Dirichlet BCs (I think)

    order is [minX, maxX, minY, maxY, minZ, maxZ]

    Returns
    -------
     bc_vals : values at the boundary conditions
     bc_flux : whether it is a Neumann boundary condition

    &#34;&#34;&#34;
    dim = self.mesh.dim
    bc_vals = np.empty(dim*2)
    bc_flux = np.empty(dim*2, dtype=bool)

    wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

    for i in range(0, dim):
        w0, w1 = wall[i]
        i0, i1 = i*2, i*2+1

        bc_vals[i0] = self.mesh.bc[w0][&#34;val&#34;]
        bc_flux[i0] = self.mesh.bc[w0][&#34;flux&#34;]

        bc_vals[i1] = self.mesh.bc[w1][&#34;val&#34;]
        bc_flux[i1] = self.mesh.bc[w1][&#34;flux&#34;]

    return bc_vals, bc_flux</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.gradient"><code class="name flex">
<span>def <span class="ident">gradient</span></span>(<span>self, f)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the derivatives of f in each dimension.</p>
<h2 id="parameters">Parameters</h2>
<p>f
: ndarray shape(n,)</p>
<h2 id="returns">Returns</h2>
<p>grad_f : ndarray shape(3,n)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gradient(self, f):
    &#34;&#34;&#34;
    Calculate the derivatives of f in each dimension.

    Parameters
    ----------
     f  : ndarray shape(n,)

    Returns
    -------
     grad_f : ndarray shape(3,n)

    &#34;&#34;&#34;
    grad = np.gradient(f.reshape(self.mesh.n), *self.grid_delta[::-1])
    return np.array(grad).reshape(self.mesh.dim, -1)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.gradient_ad"><code class="name flex">
<span>def <span class="ident">gradient_ad</span></span>(<span>self, df, f)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gradient_ad(self, df, f):
    inshape = [self.mesh.dim] + list(self.mesh.n)
    grad_ad = ad_grad(df.reshape(inshape), *self.grid_delta[::-1])
    return grad_ad.ravel()</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.heatflux"><code class="name flex">
<span>def <span class="ident">heatflux</span></span>(<span>self, T, k)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate heat flux.</p>
<h2 id="arguments">Arguments</h2>
<p>T
: ndarray shape(n,) temperature
k
: ndarray shape(n,) conductivity</p>
<h2 id="returns">Returns</h2>
<p>q
: ndarray shape(3,n), heatflux vectors</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatflux(self, T, k):
    &#34;&#34;&#34;
    Calculate heat flux.

    Arguments
    ---------
     T  : ndarray shape(n,) temperature
     k  : ndarray shape(n,) conductivity

    Returns
    -------
     q  : ndarray shape(3,n), heatflux vectors
    &#34;&#34;&#34;
    return -k*self.gradient(T)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.heatflux_ad"><code class="name flex">
<span>def <span class="ident">heatflux_ad</span></span>(<span>self, dq, q, T, k)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def heatflux_ad(self, dq, q, T, k):

    dqddelT = -k
    dqdk = -self.gradient(T)

    ddelT = dqddelT*dq
    dk = dqdk*dq

    inshape = [self.mesh.dim] + list(self.mesh.n)

    dT = self.gradient_ad(ddelT, T)

    return dT.ravel(), dk.sum(axis=0)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.in_bounds"><code class="name flex">
<span>def <span class="ident">in_bounds</span></span>(<span>self, xi)</span>
</code></dt>
<dd>
<div class="desc"><p>Find if coordinates are inside the local processor bounds</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def in_bounds(self, xi):
    &#34;&#34;&#34;
    Find if coordinates are inside the local processor bounds
    &#34;&#34;&#34;
    idx, d, bounds = self.ndinterp._find_indices(xi)
    return bounds</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.interpolate"><code class="name flex">
<span>def <span class="ident">interpolate</span></span>(<span>self, field, xi, method='nearest')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolate(self, field, xi, method=&#34;nearest&#34;):
    self.ndinterp.values = field #.reshape(self.mesh.n)
    return self.ndinterp(xi, method=method)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.interpolate_ad"><code class="name flex">
<span>def <span class="ident">interpolate_ad</span></span>(<span>self, dxi, field, xi, method='nearest')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def interpolate_ad(self, dxi, field, xi, method=&#34;nearest&#34;):
    self.ndinterp.values = field #.reshape(self.mesh.n)
    return self.ndinterp.adjoint(xi, dxi, method=method) #.ravel()</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.linear_solve"><code class="name flex">
<span>def <span class="ident">linear_solve</span></span>(<span>self, matrix=None, rhs=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def linear_solve(self, matrix=None, rhs=None):

    if matrix == None:
        matrix = self.mesh.construct_matrix()
    if rhs == None:
        rhs = self.mesh.construct_rhs()

    gvec = self.mesh.gvec
    lvec = self.mesh.lvec

    res = self.mesh.temperature
    # res._gdata.setArray(rhs._gdata)

    self.ksp.setOperators(matrix)
    self.ksp.solve(rhs._gdata, res._gdata)
    return res[:].copy()</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.linear_solve_ad"><code class="name flex">
<span>def <span class="ident">linear_solve_ad</span></span>(<span>self, T, dT, matrix=None, rhs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>If dT
= 0, adjoint=False : no need for this routine
If dT != 0 and inside lithology, lith_size &gt; 0</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def linear_solve_ad(self, T, dT, matrix=None, rhs=None):
    &#34;&#34;&#34;
    If dT  = 0, adjoint=False : no need for this routine
    If dT != 0 and inside lithology, lith_size &gt; 0
    &#34;&#34;&#34;
    adjoint = np.array(False)
    lith_size = np.array(0.0)

    idxT = np.nonzero(dT != 0.0)[0]
    nT = idxT.any()
    comm.Allreduce([nT, MPI.BOOL], [adjoint, MPI.BOOL], op=MPI.LOR)
    if adjoint:
        if matrix == None:
            matrix = self.mesh.construct_matrix(in_place=True)
        if rhs == None:
            rhs = self.mesh.rhs
        rhs[:] = dT

        gvec = self.mesh.gvec
        lvec = self.mesh.lvec

        res = self.mesh.temperature
        res[:] = T

        # adjoint b vec
        db_ad = lvec.duplicate()

        gvec.setArray(rhs._gdata)
        self.ksp.solveTranspose(rhs._gdata, gvec)
        self.mesh.dm.globalToLocal(gvec, db_ad)

        # adjoint A mat
        dk_ad = np.zeros_like(T)

        matrix.scale(-1.0)
        # self.mesh.boundary_condition(&#39;maxZ&#39;, 0.0, flux=False) # not ND!!
        dT_ad = dT[:]
        kappa = np.zeros_like(T)
        
        nl = len(self.lithology_index)
        for i in range(0, nl):
            # find if there are nonzero dT that intersect a lithology
            idxM  = self.lithology_mask[i]
            idx_n = np.intersect1d(idxT, idxM)
            gnodes = self.ghost_weights[idx_n]
            local_size = np.array(float(idx_n.size)) - np.sum(1.0 - 1.0/gnodes) # ghost nodes
            comm.Allreduce([local_size, MPI.DOUBLE], [lith_size, MPI.DOUBLE], op=MPI.SUM)
            # print comm.rank, i, lith_size, idx_n.size

            if lith_size &gt; 0:
                kappa.fill(0.0)
                kappa[idxM] = 1.0
                self.mesh.diffusivity[:] = kappa
                dAdkl = self.mesh.construct_matrix(in_place=False, derivative=True)
                dAdklT = dAdkl * res._gdata
                gvec.setArray(dAdklT) # try make the solution somewhat close
                self.ksp.solve(dAdklT, gvec)
                self.mesh.dm.globalToLocal(gvec, lvec)

                # need to call sum on the global vec
                dk_local = (dT_ad*lvec.array)/lith_size
                lvec.setArray(dk_local)
                self.mesh.dm.localToGlobal(lvec, gvec)
                gdot = gvec.sum()

                if local_size &gt; 0:
                    # splatter inside vector
                    dk_ad[idx_n] += gdot

        dk_ad = self.mesh.sync(dk_ad)


        return dk_ad, db_ad.array
    else:
        return np.zeros_like(T), np.zeros_like(T)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.lookup_velocity"><code class="name flex">
<span>def <span class="ident">lookup_velocity</span></span>(<span>self, T=None, P=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Lookup velocity from VelocityTable object (vtable)</p>
<h2 id="parameters">Parameters</h2>
<p>T
: temperature (optional)
taken from active mesh variable if not given
P
: pressure (optional)
calculated from depth assuming a constant density of 2700 kg/m^3</p>
<h2 id="returns">Returns</h2>
<p>table
: everything in the table for given nodes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lookup_velocity(self, T=None, P=None):
    &#34;&#34;&#34;
    Lookup velocity from VelocityTable object (vtable)

    Parameters
    ----------
     T  : temperature (optional)
       taken from active mesh variable if not given
     P  : pressure (optional)
       calculated from depth assuming a constant density of 2700 kg/m^3
    
    Returns
    -------
     table  : everything in the table for given nodes

    &#34;&#34;&#34;
    if T is None:
        T = self.mesh.temperature[:]
    if P is None:
        z = np.absolute(self.mesh.coords[:,-1])

        rho = 2700.0
        r = 6.38e6 # radius of the Earth
        M = 5.98e24 # mass of the Earth
        G = 6.673e-11 # gravitational constant
        g = G*M/(r-z)**2
        P = rho*g*z*1e-5

    nl = len(self.lithology_index)
    nf = self.TPtable.ncol

    # preallocate memory
    V = np.zeros((nf, self.mesh.nn))

    for i in range(0, nl):
        idx = self.lithology_mask[i]
        lith_idx = self.lithology_index[i]
        V[:,idx] = self.TPtable(T[idx], P[idx], lith_idx).T

    return V</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.map"><code class="name flex">
<span>def <span class="ident">map</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Requires a tuple of vectors corresponding to an inversion variable
these are mapped to the mesh.</p>
<p>tuple(vec1, vec2, vecN) &ndash;&gt; tuple(field1, field2, fieldN)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map(self, *args):
    &#34;&#34;&#34;
    Requires a tuple of vectors corresponding to an inversion variable
    these are mapped to the mesh.

    tuple(vec1, vec2, vecN) --&gt; tuple(field1, field2, fieldN)
    &#34;&#34;&#34;

    nf = len(args)
    nl = len(self.lithology_index)

    # preallocate local memory
    mesh_variables = np.zeros((nf, self.mesh.nn))

    # unpack vector to field
    for i in range(0, nl):
        idx = self.lithology_mask[i]
        for f in range(nf):
            mesh_variables[f,idx] = args[f][i]

    # sync fields across processors
    for f in range(nf):
        mesh_variables[f] = self.mesh.sync(mesh_variables[f])

    return list(mesh_variables)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.map_ad"><code class="name flex">
<span>def <span class="ident">map_ad</span></span>(<span>self, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Map mesh variables back to the list</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_ad(self, *args):
    &#34;&#34;&#34;
    Map mesh variables back to the list
    &#34;&#34;&#34;
    
    nf = len(args)
    nl = len(self.lithology_index)

    # sync fields across processors
    mesh_variables = np.zeros((nf, self.mesh.nn))
    for f in range(nf):
        mesh_variables[f] = self.mesh.sync(args[f])

    lith_variables = np.zeros((nf, self.lithology_index.size))
    all_lith_variables = np.zeros_like(lith_variables)

    for i in range(0, nl):
        idx = self.lithology_mask[i]
        for f in range(nf):
            lith_variables[f,i] += (mesh_variables[f]/self.ghost_weights)[idx].sum()

    comm.Allreduce([lith_variables, MPI.DOUBLE], [all_lith_variables, MPI.DOUBLE], op=MPI.SUM)

    return list(all_lith_variables)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.map_wall"><code class="name flex">
<span>def <span class="ident">map_wall</span></span>(<span>self, wall, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>Map lists of arguments to a boundary wall</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_wall(self, wall, *args):
    &#34;&#34;&#34;
    Map lists of arguments to a boundary wall


    &#34;&#34;&#34;

    if wall not in self.mesh.bc:
        raise ValueError(&#34;wall must be one of {}&#34;.format(self.mesh.bc.keys()))
    if len(args) +1 != self.mesh.dim:
        # +1 because it&#39;s a plane
        raise ValueError(&#34;dimensions of lists must equal number of dimensions&#34;)

    axis = None

    sizes = list(self.mesh.dm.getSizes())
    sizes.pop(axis)
    extent = np.reshape(self.mesh.extent, (-1,2))
    extent_bc = np.delete(extent, axis, axis=0)

    gcoords = []
    sizes = []
    for i in self.mesh.dim:
        if i != axis:
            coords = self.mesh.grid_coords[i]
            gcoords.append(coords)
            sizes.append(coords.size)

    ix = np.meshgrid(gcoords)
    
    # 0. divide wall into chunks based on the length of args
    # 1. find if proc contains bc mask
    # 2. map chunk to the bc



    bc_mask = self.mesh.bc[bc][&#39;mask&#39;]
    if bc_mask.any():
        pass</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.objective_function"><code class="name flex">
<span>def <span class="ident">objective_function</span></span>(<span>self, x, x0, sigma_x0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def objective_function(self, x, x0, sigma_x0):
    return np.sum(0.5*(x - x0)**2/sigma_x0**2)</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.objective_function_ad"><code class="name flex">
<span>def <span class="ident">objective_function_ad</span></span>(<span>self, x, x0, sigma_x0)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def objective_function_ad(self, x, x0, sigma_x0):
    return 0.5*(2.0*x - 2.0*x0)/sigma_x0**2</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.objective_function_lstsq"><code class="name flex">
<span>def <span class="ident">objective_function_lstsq</span></span>(<span>self, x, x0, cov)</span>
</code></dt>
<dd>
<div class="desc"><p>Nonlinear least squares objective function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def objective_function_lstsq(self, x, x0, cov):
    &#34;&#34;&#34;
    Nonlinear least squares objective function
    &#34;&#34;&#34;
    ksp = self._initialise_ksp(cov, pc=&#39;lu&#39;)
    misfit = np.array(x - x0)
    lhs, rhs = cov.createVecs()
    rhs.set(0.0)
    lindices = np.arange(0, misfit.size, dtype=PETSc.IntType)
    rhs.setValues(lindices, misfit, PETSc.InsertMode.ADD_VALUES)
    rhs.assemble()
    ksp.solve(rhs, lhs)
    sol = rhs*lhs
    sol.scale(0.5)

    ksp.destroy()
    lhs.destroy()
    rhs.destroy()

    return sol.sum()/comm.size</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.objective_function_lstsq_ad"><code class="name flex">
<span>def <span class="ident">objective_function_lstsq_ad</span></span>(<span>self, x, x0, cov)</span>
</code></dt>
<dd>
<div class="desc"><p>Adjoint of the nonlinear least squares objective function</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def objective_function_lstsq_ad(self, x, x0, cov):
    &#34;&#34;&#34;
    Adjoint of the nonlinear least squares objective function
    &#34;&#34;&#34;
    ksp = self._initialise_ksp(cov, pc=&#39;lu&#39;)

    misfit = np.array(x - x0)
    lhs, rhs = cov.createVecs()
    rhs.set(0.0)
    lindices = np.arange(0, misfit.size, dtype=PETSc.IntType)
    rhs.setValues(lindices, misfit, PETSc.InsertMode.ADD_VALUES)
    rhs.assemble()
    ksp.solve(rhs, lhs)

    toall, allvec = PETSc.Scatter.toAll(lhs)
    toall.scatter(lhs, allvec, PETSc.InsertMode.INSERT)

    ksp.destroy()
    lhs.destroy()
    return allvec.array</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.objective_routine"><code class="name flex">
<span>def <span class="ident">objective_routine</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>This always comes at the end of the forward model (beginning of the adjoint)
so we can safely roll interpolation, cost into one method.</p>
<p>Argument is a field if it is an observation - so that we can interpolate it.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def objective_routine(self, **kwargs):
    &#34;&#34;&#34;
    This always comes at the end of the forward model (beginning of the adjoint)
    so we can safely roll interpolation, cost into one method.

    Argument is a field if it is an observation - so that we can interpolate it.
    &#34;&#34;&#34;

    # ensure an objective function is provided
    # if self.objective_function is None:
        # raise ValueError(&#34;Pass an objective function&#34;)

    c = np.array(0.0) # local prior values same as global
    c_obs = np.array(0.0) # obs have to be summed over all procs
    c_all = np.array(0.0) # sum of all obs

    for arg in kwargs:
        val = kwargs[arg]
        if arg in self.prior:
            prior = self.prior[arg]

            if prior.cov is None:
                c += self.objective_function(val, prior.v, prior.dv)
            else:
                c += self.objective_function_lstsq(val, prior.v, prior.cov)
        elif arg in self.observation:
            obs = self.observation[arg]

            # interpolation
            ival = self.interpolate(val, obs.coords)

            # weighting for ghost nodes
            if obs.cov is None:
                c_obs += self.objective_function(ival*obs.w, obs.v*obs.w, obs.dv)
            else:
                c_obs += self.objective_function_lstsq(ival*obs.w, obs.v*obs.w, obs.cov)



    comm.Allreduce([c_obs, MPI.DOUBLE], [c_all, MPI.DOUBLE], op=MPI.SUM)
    c += c_all
    return c</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.objective_routine_ad"><code class="name flex">
<span>def <span class="ident">objective_routine_ad</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def objective_routine_ad(self, **kwargs):

    dcdv = 0.0

    for arg in kwargs:
        val = kwargs[arg]
        if arg in self.prior:
            prior = self.prior[arg]
            if prior.cov is None:
                dcdv = self.objective_function_ad(val, prior.v, prior.dv)
            else:
                dcdv = self.objective_function_lstsq_ad(val, prior.v, prior.cov)

        elif arg in self.observation:
            obs = self.observation[arg]

            ival = self.interpolate(val, obs.coords)


            if obs.cov is None:
                dcdinterp = self.objective_function_ad(ival, obs.v, obs.dv)
            else:
                dcdinterp = self.objective_function_lstsq_ad(ival*obs.w, obs.v*obs.w, obs.cov)

            # interpolation
            dcdv = self.interpolate_ad(dcdinterp, val, obs.coords)
            # print arg, np.shape(val), np.shape(ival), np.shape(dcdv)

            # sync
            dcdv = self.mesh.sync(dcdv)
        else:
            dcdv = np.zeros_like(val)

    return dcdv</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.set_boundary_conditions"><code class="name flex">
<span>def <span class="ident">set_boundary_conditions</span></span>(<span>self, bc_vals, bc_flux)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the boundary conditions easily using two vectors
order is [minX, maxX, minY, maxY, minZ, maxZ]</p>
<h2 id="parameters">Parameters</h2>
<p>bc_vals : values at the boundary conditions
bc_flux : whether it is a Neumann boundary condition</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_boundary_conditions(self, bc_vals, bc_flux):
    &#34;&#34;&#34;
    Set the boundary conditions easily using two vectors
    order is [minX, maxX, minY, maxY, minZ, maxZ]

    Parameters
    -------
     bc_vals : values at the boundary conditions
     bc_flux : whether it is a Neumann boundary condition

    &#34;&#34;&#34;
    dim = self.mesh.dim
    if len(bc_vals) != len(bc_flux) or len(bc_vals) != dim*2:
        raise ValueError(&#34;Input vectors should be of size {}&#34;.format(dim*2))

    wall = [(&#34;minX&#34;, &#34;maxX&#34;), (&#34;minY&#34;, &#34;maxY&#34;), (&#34;minZ&#34;, &#34;maxZ&#34;)]

    for i in range(0, dim):
        w0, w1 = wall[i]
        i0, i1 = i*2, i*2+1

        self.mesh.bc[w0][&#34;val&#34;]  = bc_vals[i0]
        self.mesh.bc[w0][&#34;flux&#34;] = bc_flux[i0]

        self.mesh.bc[w1][&#34;val&#34;]  = bc_vals[i1]
        self.mesh.bc[w1][&#34;flux&#34;] = bc_flux[i1]</code></pre>
</details>
</dd>
<dt id="conduction.inversion.nd_inverse_conduction.InversionND.update_lithology"><code class="name flex">
<span>def <span class="ident">update_lithology</span></span>(<span>self, new_lithology, lithology_index=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Update the configuration of lithologies.</p>
<p>Internal mask structures are updated to reflect the change in
lithology configuration.</p>
<h2 id="arguments">Arguments</h2>
<p>new_lithology
: field on the mesh with integers indicating
: the position of particular lithologies
lithology_index : array corresponding to the total number of
: integers in new_lithology</p>
<h2 id="notes">Notes</h2>
<p>lithology_index is determined from the min/max of elements
in new_lithology if lithology_index=None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_lithology(self, new_lithology, lithology_index=None):
    &#34;&#34;&#34;
    Update the configuration of lithologies.

    Internal mask structures are updated to reflect the change in
    lithology configuration.

    Arguments
    ---------
     new_lithology   : field on the mesh with integers indicating
        : the position of particular lithologies
     lithology_index : array corresponding to the total number of
        : integers in new_lithology
    
    Notes
    -----
     lithology_index is determined from the min/max of elements
     in new_lithology if lithology_index=None
    &#34;&#34;&#34;

    new_lithology = np.array(new_lithology).ravel()

    # sync across processors
    new_lithology = self.mesh.sync(new_lithology)
    new_lithology = new_lithology.astype(np.int)

    if type(lithology_index) == type(None):
        # query global vector for minx/max
        iloc, lith_min = self.mesh.gvec.min()
        iloc, lith_max = self.mesh.gvec.max()

        # create lithology index
        lithology_index = np.arange(int(lith_min), int(lith_max)+1)


    nl = len(lithology_index)
    lithology_mask = [i for i in range(nl)]

    # create lithology mask
    for i, index in enumerate(lithology_index):
        lithology_mask[i] = np.nonzero(new_lithology == index)[0]

    self.lithology_mask = lithology_mask
    self.lithology_index = lithology_index
    self._lithology = new_lithology

    return</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="conduction.inversion" href="index.html">conduction.inversion</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="conduction.inversion.nd_inverse_conduction.InversionND" href="#conduction.inversion.nd_inverse_conduction.InversionND">InversionND</a></code></h4>
<ul class="">
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.add_observation" href="#conduction.inversion.nd_inverse_conduction.InversionND.add_observation">add_observation</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.add_perplex_table" href="#conduction.inversion.nd_inverse_conduction.InversionND.add_perplex_table">add_perplex_table</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.add_prior" href="#conduction.inversion.nd_inverse_conduction.InversionND.add_prior">add_prior</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.create_covariance_matrix" href="#conduction.inversion.nd_inverse_conduction.InversionND.create_covariance_matrix">create_covariance_matrix</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.create_covariance_matrix_kdtree" href="#conduction.inversion.nd_inverse_conduction.InversionND.create_covariance_matrix_kdtree">create_covariance_matrix_kdtree</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.create_wall_map" href="#conduction.inversion.nd_inverse_conduction.InversionND.create_wall_map">create_wall_map</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.get_boundary_conditions" href="#conduction.inversion.nd_inverse_conduction.InversionND.get_boundary_conditions">get_boundary_conditions</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.gradient" href="#conduction.inversion.nd_inverse_conduction.InversionND.gradient">gradient</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.gradient_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.gradient_ad">gradient_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.heatflux" href="#conduction.inversion.nd_inverse_conduction.InversionND.heatflux">heatflux</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.heatflux_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.heatflux_ad">heatflux_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.in_bounds" href="#conduction.inversion.nd_inverse_conduction.InversionND.in_bounds">in_bounds</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.interpolate" href="#conduction.inversion.nd_inverse_conduction.InversionND.interpolate">interpolate</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.interpolate_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.interpolate_ad">interpolate_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.linear_solve" href="#conduction.inversion.nd_inverse_conduction.InversionND.linear_solve">linear_solve</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.linear_solve_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.linear_solve_ad">linear_solve_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.lithology" href="#conduction.inversion.nd_inverse_conduction.InversionND.lithology">lithology</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.lookup_velocity" href="#conduction.inversion.nd_inverse_conduction.InversionND.lookup_velocity">lookup_velocity</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.map" href="#conduction.inversion.nd_inverse_conduction.InversionND.map">map</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.map_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.map_ad">map_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.map_wall" href="#conduction.inversion.nd_inverse_conduction.InversionND.map_wall">map_wall</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.objective_function" href="#conduction.inversion.nd_inverse_conduction.InversionND.objective_function">objective_function</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.objective_function_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.objective_function_ad">objective_function_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.objective_function_lstsq" href="#conduction.inversion.nd_inverse_conduction.InversionND.objective_function_lstsq">objective_function_lstsq</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.objective_function_lstsq_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.objective_function_lstsq_ad">objective_function_lstsq_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.objective_routine" href="#conduction.inversion.nd_inverse_conduction.InversionND.objective_routine">objective_routine</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.objective_routine_ad" href="#conduction.inversion.nd_inverse_conduction.InversionND.objective_routine_ad">objective_routine_ad</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.set_boundary_conditions" href="#conduction.inversion.nd_inverse_conduction.InversionND.set_boundary_conditions">set_boundary_conditions</a></code></li>
<li><code><a title="conduction.inversion.nd_inverse_conduction.InversionND.update_lithology" href="#conduction.inversion.nd_inverse_conduction.InversionND.update_lithology">update_lithology</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>